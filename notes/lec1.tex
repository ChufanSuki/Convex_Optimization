%
% This is a borrowed LaTeX template file for lecture notes for CS267,
% Applications of Parallel Computing, UC Berkeley EECS Department.
% Now being used for Carnegie Mellon University's 10-725/36-725 
% Convex Optimization course taught by Ryan Tibshirani.  When
% preparing LaTeX notes for this class, please use this template. 
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi. "pdflatex template.tex" should also work.
%

\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%

\usepackage{amsmath,amsfonts,graphicx}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf Convex 
        Optimization \hfill Fall 2021} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribes: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}

   {\bf Note}: {\it LaTeX template courtesy of UC Berkeley EECS dept.}

   {\bf Disclaimer}: {\it These notes have not been subjected to the
   usual scrutiny reserved for formal publications. They may be
   distributed outside this class only with the permission of the
   Instructor.} \vspace*{4mm}
}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand\E{\mathbb{E}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{1}{October 14}{Ryan Tibshirani}{Chufan Chen}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

\section{Vectors}
$$x \in \mathbb{R}^n$$
$$x = \left[\begin{array}{@{}c@{}}
    x_{1} \\
    \vdots \\
    x_{n} 
    \end{array} \right]$$
Convention: $\mathbb{R}^n$ is comprised of column vectors.\\
Transpose: $x^T = [x_1 \hdots x_n]$ (row vectors)\\
$x^{TT}=x$

\subsection{Complex Vectors}

For $x \in \mathbb{C}$, its complex conjugate is denoted $x^*$.\\
For $x \in \mathbb{C}$ (column vector), its transpose is denoted $x^T$.\\
The complex conjugate transpose (aka conjugate transpose aka Hermitian transpose) of $x \in \mathbb(C)$ is denoted $x^*$.\\
$x^{**}=x$.\\

\subsection{Span, Linearly independent, Basis}
The span of $\{x^{(1)}\hdots x^{(d)}\}$ is the set of vectors that can be expressed in the form $\sum_{i=1}^{d}{a_{i}x}^{(i)}$, where $a_i \in \mathbb{R}$.\\
$\{x^{(1)}\hdots x^{(d)}\}$ are said to be linearly independent if 
\[
\sum_{i=1}^{d}{a_{i}x}^{(i)}=0 \implies a_i=0 \forall i
\]
$\{x^{(1)}\hdots x^{(d)}\}$ is a basis for $\mathbb{R}^n$ if the vectors are linearly independent and span  $\mathbb{R}^n$.

\subsection{Change of  basis in $\mathbb{R}^n$}
Here $\{u_1,u_2\}$ is a basis, $\{v_1,v_2\}$ is another basis got from $\{u_1,u_2\}$ by counterclockwise rotation by $\theta$.\\
$v_1$ has representation $ \begin{bmatrix}
           cos\theta \\
           sin\theta
         \end{bmatrix}$ 
in basis $\{u_1,u_2\}$.\\
$v_1$ has representation $ \begin{bmatrix}
           1 \\
           0
         \end{bmatrix}$ 
in basis $\{v_1,v_2\}$.\\
$v_2$ has representation $ \begin{bmatrix}
           -sin\theta \\
           cos\theta
         \end{bmatrix}$ 
in basis $\{u_1,u_2\}$.\\
$v_2$ has representation $ \begin{bmatrix}
           0 \\
           1
         \end{bmatrix}$ 
in basis $\{v_1,v_2\}$.\\
So if $x$ has representation $ \begin{bmatrix}
           a \\
           b
\end{bmatrix}$ in $\{v_1,v_2\}$ basis, then it has representation $a\begin{bmatrix}
           cos\theta \\
           sin\theta
\end{bmatrix}+b\begin{bmatrix}
           -sin\theta \\
           cos\theta
\end{bmatrix} = \begin{bmatrix}
           \widetilde{a}\\
           \widetilde{b}
\end{bmatrix} $ in $\{u_1,u_2\}$ basis.\\
$
\begin{bmatrix}
           \widetilde{a}\\
           \widetilde{b}
\end{bmatrix}=
\begin{bmatrix}
\cos\theta & -\sin\theta \\
\sin\theta & \cos\theta
\end{bmatrix}
\begin{bmatrix}
           a\\
           b
\end{bmatrix}$

\begin{lemma}Scaling, addition, linear independence preserved after change of basis.\end{lemma}
\begin{proof}
If $x=
\begin{bmatrix}
a\\
b
\end{bmatrix}$
 in first basis and
$\begin{bmatrix}
           \widetilde{a}\\
           \widetilde{b}
\end{bmatrix}$ in second basis and $\alpha \in \mathbb{R}$.
The $\alpha x = \begin{bmatrix}
\alpha a\\
\alpha b
\end{bmatrix}$ in first basis and the representation of $\alpha x$ in the second basis is $\begin{bmatrix}
\alpha \widetilde{a}\\
\alpha \widetilde{b}
\end{bmatrix}$.\\
Similarly representation of $x +y$ in the second basis = representation of $x$ in second basis + representation of $y$ in second basis.\\
Clearly linearly independence of vectors holds or doesn't hold in all bases.
\end{proof}
\subsection{Abstract notion of a vector space}
A set $\mathcal{V}$ comprised of vectors.\\
A specific element in \(\mathcal{V}\) called the zero vector (denote 0).\\
Given $\alpha \in \mathbb{R}, v \in  \mathcal{V}$ there is an element in  $\mathcal{V}$ denoted $\alpha v$(scaling).\\
Given $v,w \in  \mathcal{V}$ there is an element denoted $v+w\in  \mathcal{V}$(sum of $v$ and $w$).\\
Must have, for all $u,v,w \in \mathcal{V}$, $\alpha,\beta \in \mathbb{R}$,
\begin{itemize}
\item $v+w=w+v$
\item $u+(v+w)=(u+v)+w$
\item $v+0=v$
\item $-v+v=0$
\item zero scaling of $v$ is the zero vector (i.e. $0v=0$)
\item scaling of $v$ by 1 gives $v$(i.e. $1v=v$)
\item $\alpha(\beta v)=(\alpha \beta)v$
\item $\alpha(u+v)=\alpha u+\alpha v$
\item $(\alpha+ \beta) v=\alpha v + \beta v$
\end{itemize}

\subsection{Subspaces, span, basis, dimension, direct sum, in a vector space}
A subspace of the vector space $\mathcal{V}$ is a subset that is closed under scaling and vector addition.\\
The span of $\{x^{(1}\hdots x^{(d}\}$ are said to be linearly independent if $\sum_{i=1}a_ix^{(i)}=0 \implies a_i=0 \forall i$\\
$\{x^{(1}\hdots x^{(d}\}$ is a basis for $\mathcal{V}$ if the vectors are linearly independent and span $\mathcal{V}$.\\
A finite dimensional vector space is one with a finite basis.\\
Every basis in a finite dimensional vector space has the same cardinality. This is called the dimension of the vector space.

\begin{lemma}
Dimension of a finite dimensional vector space is well defined.
\end{lemma}

\begin{proof}
Let $\{b_1\hdots b_d\}$ be a basis for $\mathcal{V}$.\\
Let $\{w_1 w_2 \hdots \}$ be another basis $\mathcal{V}$(with at least $d$ elements).\\
Take $w_1$, it can be written as $\sum_{k=1}^d a_k b_k$. This means some $b_i$ can be replaced by $w_1$.\\
So $\{b_1\hdots b_{i-1}, w_1, b_{i+1}\hdots b_d\}$ is a basis.\\
Similarly, use $w_2$ to replace some $b_j$, $j \neq i$.
\end{proof}


\subsection{Finite dimensional vector space can be identified with $\mathbb{R}^n$ after the choice of basis}
Let $\{b^{(1}\hdots b^{(d}\}$ be a basis.\\
Write $x=\sum_{i=1}^{d}a_ib^{(i)} $.\\
The coefficients $a_i \hdots a_d$ are uniquely defined.\\
This gives a representation of $x$ as $\begin{bmatrix}
a_1\\
\vdots \\
a_d
\end{bmatrix}$

\subsection{Affine translation of a subspace}
$\mathcal{A}=\{x^{(0)}+\mathcal{S}\}$, $x^{(0)} \in \mathcal{V}$, $\mathcal{S}$ subspace of $\mathcal{V}$,
$\mathcal{A}$ is called an affine translation of the subspace $\mathcal{S}$.

\subsection{Norm on a vector space}
A way of measuring $x \in mathcal{V}$ via $||\cdot||: \mathcal{V}\implies \mathbb{R}_{\ge 0}$.\\
Requirements:\\
$||x||\ge 0$ for all $x$, with equlaity iff $x=0$.\\
$||x+y||\le ||x||+||y||$ for $x,y\in \mathcal{V}$.\\
$||\alpha x||=|\alpha|||x||$ for $\alpha \in \mathbb{R}$, $x\in\mathcal{V}$.\\
$||x||_2$ for $x \in \mathbb{R}^n$, $||x||_2=(\sum_{i=1}^{n}{x_i^2})^{1/2}$.($l_2$norm)\\
$||x||_1=\sum_{i=1}^{n}{|x_i|}$.($l_1$norm)\\
$||x||_{\infty}=\max_{i}{x_i}$.($l_{\infty}$norm)

\subsection{Unit balls in $l_p$ norms}

\subsection{Inner product space}
Motivated by the construction of $x^Ty$ for $x,y\in \mathbb{R}^n$\\
Inner product on a vector space:\\
For all $x,y,z \in \mathcal{V}, \alpha \in \mathbb{R}$, we have:\\
\begin{itemize}
\item $<x,x> \ge 0$
\item $<x,x>=0$iff $x=0$
\item $<x,y>=<y,x>$
\item $<x,y+z>=<x,y>+<x,z>$
\item $<\alpha x,y>=\alpha<x,y>$
\end{itemize}
In a inner product space $\sqrt{<x,x>}$ is a norm, which we can write as $||x||_2$.\\
In $\mathbb{R}^n$ with its usual inner product and only in this case we will use $<x,y> $ and $x^Ty$ interchangebly. 

\subsection{Orthogonality and angle between vectors in an inner product space}
Suppose $x,y \in \mathbb{R}^n$, then we can talk about the angle between them by restricting attention to the 2-dimensional subspace they span.\\
It is defined by $\cos \theta=\frac{x^T y}{||x||_2 ||y||_2}$.
$z=x-y$, $||z||_2^2=(||y||_2\sin\theta)^2+||x-(y||_2\cos\theta)^2$ and $||z||_2^2=(x-y)^T(x-y)=||x||_2^2+||y||_2^2-2x^Ty$.\\
This leads us to define the angle between two vector $x$ and $y$ in an inner product space as $\cos\theta=\frac{<x,y>}{\sqrt{<x,x><y,y>}}$.\\
$x$ and $y$ are called orthogonal iff $<x,y>=0$.

\begin{theorem}
Cauchy-Schwarz inequality\\
$|x^Ty|\le ||x||_2||y||_2$ in $\mathbb{R}^n$\\

\end{theorem}

\begin{proof}

This concludes the proof.
\end{proof}

\begin{theorem}
   Holder inequality\\
   $|x^Ty|\le ||x||_2||y||_2$ in $\mathbb{R}^n$\\
   
\end{theorem}
   
\begin{proof}
   
   This concludes the proof.
\end{proof}

\subsection{Orthonorma basis in an inner product space}
A basis $\{b_1\hdots b_n\}$ for $\mathbb{R}^n$ as an inner product space of n dimension is called orthonormal if\\
 $<b_i, b_i>=1$ for all $i$\\
$<b_i,b_j>=0$ if $i \neq j$.

\subsection{Gram-Schmidt process}
Starting with a basis in $\mathbb{R}^n$ produce an orthonormal basis.

\section{Reading}

Read ~\cite{OM} Ch.1,Ch.2.

\section*{References}
\beginrefs
\bibentry{OM}{\sc Giuseppe C. Calafiore} and {\sc Laurent El Ghaoui}, 
``Optimization Models,''
{\it Cambridge University Press, Control systems and optimization series},
2014.
\endrefs

% **** THIS ENDS THE EXAMPLES. DON'T DELETE THE FOLLOWING LINE:

\end{document}
